{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist GAN eager execution\n",
    "---\n",
    "\n",
    "<font color='red'> <h3>Tested with TensorFlow 1.7</h3></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_eager_gan():\n",
    "\n",
    "    \"\"\"A deep MNIST classifier using convolutional layers.\n",
    "    Sample usage:\n",
    "      python mnist.py --help\n",
    "    \"\"\"\n",
    "    import argparse\n",
    "    import os\n",
    "    import sys\n",
    "    import time\n",
    "\n",
    "    import tensorflow as tf\n",
    "\n",
    "    import tensorflow.contrib.eager as tfe\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    \n",
    "    from hops import tensorboard\n",
    "    from hops import hdfs\n",
    "\n",
    "    layers = tf.keras.layers\n",
    "    \n",
    "    data_dir = os.getcwd()\n",
    "    log_interval = 20\n",
    "    noise = 100\n",
    "    lr = 0.001\n",
    "    batch_size = 128\n",
    "\n",
    "\n",
    "    class Discriminator(tf.keras.Model):\n",
    "      \"\"\"GAN Discriminator.\n",
    "      A network to differentiate between generated and real handwritten digits.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self, data_format):\n",
    "        \"\"\"Creates a model for discriminating between real and generated digits.\n",
    "        Args:\n",
    "          data_format: Either 'channels_first' or 'channels_last'.\n",
    "            'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "            typically faster on CPUs. See\n",
    "            https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "        \"\"\"\n",
    "        super(Discriminator, self).__init__(name='')\n",
    "        if data_format == 'channels_first':\n",
    "          self._input_shape = [-1, 1, 28, 28]\n",
    "        else:\n",
    "          assert data_format == 'channels_last'\n",
    "          self._input_shape = [-1, 28, 28, 1]\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            64, 5, padding='SAME', data_format=data_format, activation=tf.tanh)\n",
    "        self.pool1 = layers.AveragePooling2D(2, 2, data_format=data_format)\n",
    "        self.conv2 = layers.Conv2D(\n",
    "            128, 5, data_format=data_format, activation=tf.tanh)\n",
    "        self.pool2 = layers.AveragePooling2D(2, 2, data_format=data_format)\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(1024, activation=tf.tanh)\n",
    "        self.fc2 = layers.Dense(1, activation=None)\n",
    "\n",
    "      def call(self, inputs):\n",
    "        \"\"\"Return two logits per image estimating input authenticity.\n",
    "        Users should invoke __call__ to run the network, which delegates to this\n",
    "        method (and not call this method directly).\n",
    "        Args:\n",
    "          inputs: A batch of images as a Tensor with shape [batch_size, 28, 28, 1]\n",
    "            or [batch_size, 1, 28, 28]\n",
    "        Returns:\n",
    "          A Tensor with shape [batch_size] containing logits estimating\n",
    "          the probability that corresponding digit is real.\n",
    "        \"\"\"\n",
    "        x = tf.reshape(inputs, self._input_shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    class Generator(tf.keras.Model):\n",
    "      \"\"\"Generator of handwritten digits similar to the ones in the MNIST dataset.\n",
    "      \"\"\"\n",
    "\n",
    "      def __init__(self, data_format):\n",
    "        \"\"\"Creates a model for discriminating between real and generated digits.\n",
    "        Args:\n",
    "          data_format: Either 'channels_first' or 'channels_last'.\n",
    "            'channels_first' is typically faster on GPUs while 'channels_last' is\n",
    "            typically faster on CPUs. See\n",
    "            https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__(name='')\n",
    "        self.data_format = data_format\n",
    "        # We are using 128 6x6 channels as input to the first deconvolution layer\n",
    "        if data_format == 'channels_first':\n",
    "          self._pre_conv_shape = [-1, 128, 6, 6]\n",
    "        else:\n",
    "          assert data_format == 'channels_last'\n",
    "          self._pre_conv_shape = [-1, 6, 6, 128]\n",
    "        self.fc1 = layers.Dense(6 * 6 * 128, activation=tf.tanh)\n",
    "\n",
    "        # In call(), we reshape the output of fc1 to _pre_conv_shape\n",
    "\n",
    "        # Deconvolution layer. Resulting image shape: (batch, 14, 14, 64)\n",
    "        self.conv1 = layers.Conv2DTranspose(\n",
    "            64, 4, strides=2, activation=None, data_format=data_format)\n",
    "\n",
    "        # Deconvolution layer. Resulting image shape: (batch, 28, 28, 1)\n",
    "        self.conv2 = layers.Conv2DTranspose(\n",
    "            1, 2, strides=2, activation=tf.nn.sigmoid, data_format=data_format)\n",
    "\n",
    "      def call(self, inputs):\n",
    "        \"\"\"Return a batch of generated images.\n",
    "        Users should invoke __call__ to run the network, which delegates to this\n",
    "        method (and not call this method directly).\n",
    "        Args:\n",
    "          inputs: A batch of noise vectors as a Tensor with shape\n",
    "            [batch_size, length of noise vectors].\n",
    "        Returns:\n",
    "          A Tensor containing generated images. If data_format is 'channels_last',\n",
    "          the shape of returned images is [batch_size, 28, 28, 1], else\n",
    "          [batch_size, 1, 28, 28]\n",
    "        \"\"\"\n",
    "\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.reshape(x, shape=self._pre_conv_shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def discriminator_loss(discriminator_real_outputs, discriminator_gen_outputs):\n",
    "      \"\"\"Original discriminator loss for GANs, with label smoothing.\n",
    "      See `Generative Adversarial Nets` (https://arxiv.org/abs/1406.2661) for more\n",
    "      details.\n",
    "      Args:\n",
    "        discriminator_real_outputs: Discriminator output on real data.\n",
    "        discriminator_gen_outputs: Discriminator output on generated data. Expected\n",
    "          to be in the range of (-inf, inf).\n",
    "      Returns:\n",
    "        A scalar loss Tensor.\n",
    "      \"\"\"\n",
    "\n",
    "      loss_on_real = tf.losses.sigmoid_cross_entropy(\n",
    "          tf.ones_like(discriminator_real_outputs),\n",
    "          discriminator_real_outputs,\n",
    "          label_smoothing=0.25)\n",
    "      loss_on_generated = tf.losses.sigmoid_cross_entropy(\n",
    "          tf.zeros_like(discriminator_gen_outputs), discriminator_gen_outputs)\n",
    "      loss = loss_on_real + loss_on_generated\n",
    "      tf.contrib.summary.scalar('discriminator_loss', loss)\n",
    "      return loss\n",
    "\n",
    "\n",
    "    def generator_loss(discriminator_gen_outputs):\n",
    "      \"\"\"Original generator loss for GANs.\n",
    "      L = -log(sigmoid(D(G(z))))\n",
    "      See `Generative Adversarial Nets` (https://arxiv.org/abs/1406.2661)\n",
    "      for more details.\n",
    "      Args:\n",
    "        discriminator_gen_outputs: Discriminator output on generated data. Expected\n",
    "          to be in the range of (-inf, inf).\n",
    "      Returns:\n",
    "        A scalar loss Tensor.\n",
    "      \"\"\"\n",
    "      loss = tf.losses.sigmoid_cross_entropy(\n",
    "          tf.ones_like(discriminator_gen_outputs), discriminator_gen_outputs)\n",
    "      tf.contrib.summary.scalar('generator_loss', loss)\n",
    "      return loss\n",
    "\n",
    "\n",
    "    def train_one_epoch(generator, discriminator, generator_optimizer,\n",
    "                        discriminator_optimizer, dataset, step_counter,\n",
    "                        log_interval, noise_dim):\n",
    "      \"\"\"Trains `generator` and `discriminator` models on `dataset`.\n",
    "      Args:\n",
    "        generator: Generator model.\n",
    "        discriminator: Discriminator model.\n",
    "        generator_optimizer: Optimizer to use for generator.\n",
    "        discriminator_optimizer: Optimizer to use for discriminator.\n",
    "        dataset: Dataset of images to train on.\n",
    "        step_counter: An integer variable, used to write summaries regularly.\n",
    "        log_interval: How many steps to wait between logging and collecting\n",
    "          summaries.\n",
    "        noise_dim: Dimension of noise vector to use.\n",
    "      \"\"\"\n",
    "\n",
    "      total_generator_loss = 0.0\n",
    "      total_discriminator_loss = 0.0\n",
    "      for (batch_index, images) in enumerate(tfe.Iterator(dataset)):\n",
    "        with tf.device('/cpu:0'):\n",
    "          tf.assign_add(step_counter, 1)\n",
    "\n",
    "        with tf.contrib.summary.record_summaries_every_n_global_steps(\n",
    "            log_interval, global_step=step_counter):\n",
    "          current_batch_size = images.shape[0]\n",
    "          noise = tf.random_uniform(\n",
    "              shape=[current_batch_size, noise_dim],\n",
    "              minval=-1.,\n",
    "              maxval=1.,\n",
    "              seed=batch_index)\n",
    "\n",
    "          with tfe.GradientTape(persistent=True) as g:\n",
    "            generated_images = generator(noise)\n",
    "            tf.contrib.summary.image(\n",
    "                'generated_images',\n",
    "                tf.reshape(generated_images, [-1, 28, 28, 1]),\n",
    "                max_images=10)\n",
    "\n",
    "            discriminator_gen_outputs = discriminator(generated_images)\n",
    "            discriminator_real_outputs = discriminator(images)\n",
    "            discriminator_loss_val = discriminator_loss(discriminator_real_outputs,\n",
    "                                                        discriminator_gen_outputs)\n",
    "            total_discriminator_loss += discriminator_loss_val\n",
    "\n",
    "            generator_loss_val = generator_loss(discriminator_gen_outputs)\n",
    "            total_generator_loss += generator_loss_val\n",
    "\n",
    "          generator_grad = g.gradient(generator_loss_val, generator.variables)\n",
    "          discriminator_grad = g.gradient(discriminator_loss_val,\n",
    "                                          discriminator.variables)\n",
    "\n",
    "          generator_optimizer.apply_gradients(\n",
    "              zip(generator_grad, generator.variables))\n",
    "          discriminator_optimizer.apply_gradients(\n",
    "              zip(discriminator_grad, discriminator.variables))\n",
    "\n",
    "          if log_interval and batch_index > 0 and batch_index % log_interval == 0:\n",
    "            print('Batch #%d\\tAverage Generator Loss: %.6f\\t'\n",
    "                  'Average Discriminator Loss: %.6f' %\n",
    "                  (batch_index, total_generator_loss / batch_index,\n",
    "                   total_discriminator_loss / batch_index))\n",
    "            hdfs.log('Batch #%d\\tAverage Generator Loss: %.6f\\t'\n",
    "                  'Average Discriminator Loss: %.6f' %\n",
    "                  (batch_index, total_generator_loss / batch_index,\n",
    "                   total_discriminator_loss / batch_index))\n",
    "\n",
    "\n",
    "    def main(_):\n",
    "      (device, data_format) = ('/gpu:0', 'channels_first')\n",
    "      if tfe.num_gpus() == 0:\n",
    "        (device, data_format) = ('/cpu:0', 'channels_last')\n",
    "      hdfs.log('Using device %s, and data format %s.' % (device, data_format))\n",
    "      print('Using device %s, and data format %s.' % (device, data_format))\n",
    "\n",
    "      # Load the datasets\n",
    "      data = input_data.read_data_sets(data_dir)\n",
    "      dataset = (\n",
    "          tf.data.Dataset.from_tensor_slices(data.train.images).shuffle(60000)\n",
    "          .batch(batch_size))\n",
    "\n",
    "      # Create the models and optimizers.\n",
    "      model_objects = {\n",
    "          'generator': Generator(data_format),\n",
    "          'discriminator': Discriminator(data_format),\n",
    "          'generator_optimizer': tf.train.AdamOptimizer(lr),\n",
    "          'discriminator_optimizer': tf.train.AdamOptimizer(lr),\n",
    "          'step_counter': tf.train.get_or_create_global_step(),\n",
    "      }\n",
    "\n",
    "      # Prepare summary writer and checkpoint info\n",
    "      summary_writer = tf.contrib.summary.create_file_writer(\n",
    "          tensorboard.logdir(), flush_millis=1000)\n",
    "      checkpoint_prefix = os.path.join(tensorboard.logdir(), 'ckpt')\n",
    "      latest_cpkt = tf.train.latest_checkpoint(tensorboard.logdir())\n",
    "      if latest_cpkt:\n",
    "        hdfs.log('Using latest checkpoint at ' + latest_cpkt)\n",
    "        print('Using latest checkpoint at ' + latest_cpkt)\n",
    "      checkpoint = tfe.Checkpoint(**model_objects)\n",
    "      # Restore variables on creation if a checkpoint exists.\n",
    "      checkpoint.restore(latest_cpkt)\n",
    "\n",
    "      with tf.device(device):\n",
    "        for _ in range(100):\n",
    "          start = time.time()\n",
    "          with summary_writer.as_default():\n",
    "            train_one_epoch(dataset=dataset, log_interval=log_interval,\n",
    "                            noise_dim=noise, **model_objects)\n",
    "          end = time.time()\n",
    "          checkpoint.save(checkpoint_prefix)\n",
    "          hdfs.log('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "                (checkpoint.save_counter.numpy(),\n",
    "                 checkpoint.step_counter.numpy(),\n",
    "                 end - start))  \n",
    "          print('\\nTrain time for epoch #%d (step %d): %f' %\n",
    "                (checkpoint.save_counter.numpy(),\n",
    "                 checkpoint.step_counter.numpy(),\n",
    "                 end - start))\n",
    "\n",
    "\n",
    "    tfe.enable_eager_execution()\n",
    "\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid status code '400' from http://10.0.2.15:8998/sessions/33/statements/6 with error payload: \"requirement failed: Session isn't active.\"\n"
     ]
    }
   ],
   "source": [
    "from hops import experiment\n",
    "experiment.launch(spark, mnist_eager_gan, name='eager mnist gan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
