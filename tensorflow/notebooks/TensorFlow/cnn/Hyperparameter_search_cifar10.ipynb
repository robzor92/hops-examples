{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolutionary Hyperparameter Optimization: Cifar-10 on Hops Notebook\n",
    "---\n",
    "\n",
    "<font color='red'> <h3>Tested with TensorFlow 1.8</h3></font>\n",
    "\n",
    "This is a more advanced example compared to the Fashion mnist notebook which introduces the general programming model for running TensorFlow on Hops. In this example we will look into a state-of-the-art technique for finding the optimal hyperparameters for your model.\n",
    "\n",
    "In this example program we are going to:\n",
    "- Introduce the programming model for using evolutionary hyperparameter optimization on Hops\n",
    "\n",
    "## Table of contents:\n",
    "\n",
    "### [What is Hyperparameter Optimization](#whatisit)\n",
    "### [Programming model on Hops ](#cifar10)\n",
    "### [Defining search bounds ](#searchbound)\n",
    "### [Tuning the search ](#tuning)\n",
    "### [Starting the search ](#starting)\n",
    "### [Performance notes ](#performance)\n",
    "### [Visualizing the runs ](#visualize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Evolutionary Hyperparameter Optimization <a class=\"anchor\" id='whatisit'></a>\n",
    "\n",
    "Hyperparameter optimization is the process of optimizing the hyperparameters of a specific model. Evolutionary optimization is a methodology for the global optimization of noisy black-box functions. In hyperparameter optimization, evolutionary optimization uses evolutionary algorithms to search the space of hyperparameters for a given algorithm. Evolutionary hyperparameter optimization follows a process inspired by the biological concept of evolution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming model on Hops <a class=\"anchor\" id='cifar10'></a>\n",
    "\n",
    "Similar to the programming model in the fashion_mnist_on_hops notebook, the hyperparameters should be listed as arguments in a wrapper function. The wrapper function should wrap the code that you want to run.\n",
    "\n",
    "The major difference is that a metric which should be maximized or minimized should be returned by your wrapper function. In the following example we return the accuracy of the model which should be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the TensorFlow code you want to run in a function\n",
    "# To perform hyper-parameter searching define your parameters as arguments\n",
    "\n",
    "def wrapper(learning_rate, dropout, num_layers):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # Use this module to get the TensorBoard logdir\n",
    "    from hops import tensorboard\n",
    "    \n",
    "    # Use this module to get the path to your project in HopsFS, then append the path to your Dataset in your project\n",
    "    from hops import hdfs\n",
    "    \n",
    "    num_classes = 10 # CIFAR10 total classes (0-9 objects)\n",
    "    batch_size = 128\n",
    "    stride = 1\n",
    "    num_steps = 500\n",
    "    filters = 78\n",
    "    kernel = 5\n",
    "\n",
    "    # Network Parameters\n",
    "    num_input = 32*32*3 # CIFAR10 data input (img shape: 32*32*3)\n",
    "    \n",
    "    def layer(x, filters, kernel, stride):\n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv = tf.layers.conv2d(x, filters, kernel, strides=(stride, stride), activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        return tf.layers.max_pooling2d(conv, stride, stride)\n",
    "    \n",
    "    # Create the neural network\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "        \n",
    "\n",
    "        # Define a scope for reusing the variables\n",
    "        with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "\n",
    "            # CIFAR10 data input is a 1-D vector of (32*32*3 pixels)\n",
    "            # Reshape to match picture format [Height x Width x Channel]\n",
    "            # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "            x = tf.reshape(x, shape=[-1, 32, 32, 3])\n",
    "            #x = tf.image.crop_and_resize(tf.reshape(x, shape=[-1, 32, 32, 3]),size=[24,24])\n",
    "\n",
    "            h = x\n",
    "            for i in range(num_layers):\n",
    "                h = layer(h, filters, kernel, stride)\n",
    "\n",
    "            # Flatten the data to a 1-D vector for the fully connected layer\n",
    "            fc1 = tf.contrib.layers.flatten(h)\n",
    "\n",
    "            # Fully connected layer (in tf contrib folder for now)\n",
    "            fc1 = tf.layers.dense(fc1, 384)\n",
    "            # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "            fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "            \n",
    "            # Output layer, class prediction\n",
    "            out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "            return out\n",
    "    \n",
    "    # Define the model function (following TF Estimator Template)\n",
    "    def model_fn(features, labels, mode, params):\n",
    "\n",
    "        # Build the neural network\n",
    "        # Because Dropout have different behavior at training and prediction time, we\n",
    "        # need to create 2 distinct computation graphs that still share the same weights.\n",
    "        logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "        logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "\n",
    "        # Predictions\n",
    "        pred_classes = tf.argmax(logits_test, axis=1)\n",
    "        pred_probas = tf.nn.softmax(logits_test)\n",
    "\n",
    "        # If prediction mode, early return\n",
    "        if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "\n",
    "        # Evaluate the accuracy of the model\n",
    "        acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "        image = tf.reshape(features[:10], [-1, 32, 32, 3])\n",
    "        tf.summary.image(\"image\", image)\n",
    "\n",
    "        # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "        # the different ops for training, evaluating, ...\n",
    "        estim_specs = tf.estimator.EstimatorSpec(\n",
    "          mode=mode,\n",
    "          predictions=pred_classes,\n",
    "          loss=loss_op,\n",
    "          train_op=train_op,\n",
    "          eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "        return estim_specs\n",
    "    \n",
    "    def data_input_fn(filenames, num_input, batch_size=128, shuffle=False, repeat=None):\n",
    "    \n",
    "        def parser(serialized_example):\n",
    "            \"\"\"Parses a single tf.Example into image and label tensors.\"\"\"\n",
    "            features = tf.parse_single_example(\n",
    "                serialized_example,\n",
    "                features={\n",
    "                    'image': tf.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.FixedLenFeature([], tf.int64),\n",
    "                })\n",
    "            image = tf.decode_raw(features['image'], tf.uint8)\n",
    "            image.set_shape([num_input])\n",
    "\n",
    "            image = tf.cast(\n",
    "                tf.transpose(tf.reshape(image, [3, 32, 32]), [1, 2, 0]),\n",
    "                tf.float32)\n",
    "\n",
    "            # Normalize the values of the image from the range [0, 255] to [-0.5, 0.5]\n",
    "            image = tf.cast(image, tf.float32) / 255 - 0.5\n",
    "            label = tf.cast(features['label'], tf.int32)\n",
    "            return image, label\n",
    "\n",
    "        def _input_fn():\n",
    "            # Import CIFAR10 data\n",
    "            dataset = tf.data.TFRecordDataset(filenames)\n",
    "\n",
    "            # Map the parser over dataset, and batch results by up to batch_size\n",
    "            dataset = dataset.map(parser)\n",
    "            if shuffle:\n",
    "                dataset = dataset.shuffle(buffer_size=batch_size)\n",
    "            dataset = dataset.batch(batch_size)\n",
    "            dataset = dataset.repeat(repeat)\n",
    "            iterator = dataset.make_one_shot_iterator()\n",
    "\n",
    "            features, labels = iterator.get_next()\n",
    "\n",
    "            return features, labels\n",
    "\n",
    "        return _input_fn\n",
    "\n",
    "    logdir = tensorboard.logdir()\n",
    "    \n",
    "    # Path to your project in HopsFS, parent folder for your DataSets (Resources, Logs etc)\n",
    "    data_dir = hdfs.project_path()\n",
    "    train_filenames = [data_dir + \"TestJob/data/cifar10/train/train.tfrecords\"]\n",
    "    validation_filenames = [data_dir + \"TestJob/data/cifar10/validation/validation.tfrecords\"]\n",
    "\n",
    "    run_config = tf.contrib.learn.RunConfig(\n",
    "        model_dir=logdir,\n",
    "        log_device_placement=True,\n",
    "        save_checkpoints_steps=100,\n",
    "        save_summary_steps=100,\n",
    "        log_step_count_steps=100)\n",
    "    \n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        learning_rate=learning_rate, dropout_rate=dropout)\n",
    "\n",
    "    summary_hook = tf.train.SummarySaverHook(\n",
    "          save_steps = run_config.save_summary_steps,\n",
    "          scaffold= tf.train.Scaffold(),\n",
    "          summary_op=tf.summary.merge_all())\n",
    "\n",
    "    cifar10_estimator = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        config=run_config,\n",
    "        params=hparams\n",
    "    )\n",
    "\n",
    "    train_input_fn = data_input_fn(train_filenames[0], num_input, batch_size=batch_size)\n",
    "    eval_input_fn = data_input_fn(validation_filenames[0], num_input, batch_size=batch_size)\n",
    "    \n",
    "    experiment = tf.contrib.learn.Experiment(\n",
    "        cifar10_estimator,\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=eval_input_fn,\n",
    "        train_steps=num_steps,\n",
    "        min_eval_frequency=10,\n",
    "        eval_hooks=[summary_hook]\n",
    "    )\n",
    "\n",
    "    experiment.train_and_evaluate()\n",
    "    \n",
    "    accuracy_score = cifar10_estimator.evaluate(input_fn=eval_input_fn, steps=num_steps)[\"accuracy\"]\n",
    "    \n",
    "    return accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining search bounds <a class=\"anchor\" id='searchbound'></a>\n",
    "\n",
    "The next step is to define the bounds for each hyperparameter in which we should peform the search for the best hyperparameters. This is simply done by creating a dict with the name of the key corresponding to the name of the hyperparameter, and the value being an array with two elements; the lower and upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_dict = {'learning_rate': [0.005, 0.00005], 'dropout': [0.01, 0.99], 'num_layers': [1,3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning parameters <a class=\"anchor\" id='tuning'></a>\n",
    "\n",
    "Before running the optimization there are several configuration values which can be set.\n",
    "\n",
    "|   Parameter   |  Description                                                                            |           \n",
    "|:-------------:|:---------------------------------------------------------------------------------------:|\n",
    "|  direction    |  direction to optimize, 'max' or 'min'                                                  |\n",
    "|  generations  |  number of generations (how long to search)                                             |\n",
    "|  popsize      |  population per generation, the more hyperparameters the larger population              |\n",
    "|  mutation     |  mutation rate to explore more different hyperparameter configuration                   |\n",
    "|  crossover    |  how much generated hyperparameter combinations should adapt to current best combination|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the search <a class=\"anchor\" id='starting'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hops import experiment\n",
    "\n",
    "tensorboard_hdfs_logdir = experiment.evolutionary_search(spark, wrapper, boundary_dict, direction='max', popsize=10, generations=3, crossover=0.7, mutation=0.5, name='cifar10 differential evolution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance notes <a class=\"anchor\" id='performance'></a>\n",
    "\n",
    "The biggest downside of the evolutionary hyperparameter optimization is that it may spend time training networks with very poor performance as it learns better and better hyperparameter combinations. As such it is important to minimize time spent on operations which does not direcly impact the resulting metric to be maximized or minimized, a concrete example would be checkpointing the model which should be skipped - we are not interested in the model at this stage, only the hyperparameter combinations. Furthermore, operations such as early stopping could be used to avoid spending time on networks which does not improve sufficiently based on your critera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing generations and hyperparameters using TensorBoard <a class=\"anchor\" id='visualize'></a>\n",
    "\n",
    "TensorBoard provides a regex expression which can be used to easily filter out runs for each generation. The TensorBoard logdir for each generation will be put in a folder with the name generation{number}, where number corresponds to the number of the generation starting from 0. The best hyperparameter combinations are expected to appear in the later generations. Navigate to the Experiments service to visualize the generations in TensorBoard.\n",
    "\n",
    "### Generation 0\n",
    "![Image1-Tensorboard.png](../../images/generation0.png)\n",
    "### Generation 1\n",
    "![Image2-Tensorboard.png](../../images/generation1.png)\n",
    "### Generation 2\n",
    "![Image3-Tensorboard.png](../../images/generation2.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
